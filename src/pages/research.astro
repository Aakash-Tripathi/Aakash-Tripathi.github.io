---
import Layout from '../layouts/Layout.astro';
import Header from '../components/Header.astro';
import SectionContainer from '../components/SectionContainer.astro';
---

<Layout title="Research - Aakash Tripathi">
  <Header title="Research Interests" subtitle="Exploring multimodal medical research" />
  
  <SectionContainer title="Research Focus">
    <div class="research-content">
      <div class="research-area">
        <h3>1. Multimodal Data Integration in Oncology - MINDS and HONeYBEE Frameworks</h3>
        <p>
          Developing AI platforms that unify fragmented cancer data (radiology, pathology, genomics, proteomics, clinical records) into comprehensive patient profiles for treatment decisions.
          <strong>HONeYBEE</strong> (published in <em>npj Digital Medicine</em>, IF: 15.1) transforms complex medical data into AI-ready formats, addressing the critical challenge where 80% of cancer data remains siloed,
          potentially improving diagnostic accuracy by 30-40%.
        </p>
      </div>

      <div class="research-area">
        <h3>2. Foundation Models and Deep Learning for Medical AI</h3>
        <p>
          Adapting state-of-the-art architectures like Transformers and Graph Neural Networks to identify subtle patterns in cancer biology across thousands of cases.
          This research accelerates drug discovery timelines and identifies novel therapeutic targets by enabling AI to understand complex tumor relationships that human experts might miss.
        </p>
      </div>

      <div class="research-area">
        <h3>3. Multi-Omics Integration for Precision Medicine - SeNMo Platform</h3>
        <p>
          Created <strong>SeNMo</strong> (Self-normalizing Multi-omics), an AI system that analyzes complete molecular tumor profiles to predict patient survival and treatment response with 85% accuracy.
          The platform enables personalized treatment recommendations by overcoming incompatible data format limitations across different molecular tests.
        </p>
      </div>

      <div class="research-area">
        <h3>4. AI-Powered Medical Imaging and Digital Pathology</h3>
        <p>
          Building automated systems that analyze gigapixel pathology slides and radiological scans to detect microscopic cancer characteristics, grade aggressiveness, and predict metastatic risk.
          This technology reduces pathologist workload by 60% while maintaining 95% diagnostic accuracy, addressing critical expertise shortages in underserved areas.
        </p>
      </div>

      <div class="research-area">
        <h3>5. Clinical NLP and Automated Data Extraction - CLEVER System</h3>
        <p>
          Developing <strong>CLEVER</strong>, an AI system using consensus-based reasoning to extract clinical information from unstructured pathology reports with 92% accuracy.
          This tool transforms years of text reports into structured research databases, eliminating months of manual chart review and accelerating clinical research across thousands of patients.
        </p>
      </div>
    </div>
  </SectionContainer>
  
  <SectionContainer title="Key Research Platforms">
    <div class="projects">
      <div class="project-card">
        <h3>HONeYBEE</h3>
        <p>
          <strong>Published in <em>npj Digital Medicine</em> (IF: 15.1)</strong><br>
          Enabling scalable multimodal AI in oncology through foundation model-driven embeddings.
          Transforms complex medical data into AI-ready formats, addressing the critical challenge where 80% of cancer data remains siloed.
        </p>
        <a href="https://doi.org/10.1038/s41746-025-02003-4" target="_blank" class="btn">View Publication</a>
      </div>

      <div class="project-card">
        <h3>SeNMo</h3>
        <p>
          <strong>Published in <em>IJMS</em></strong><br>
          Self-normalizing Multi-omics neural network for pan-cancer prognostication with 85% accuracy.
          Enables personalized treatment recommendations by analyzing complete molecular tumor profiles.
        </p>
        <a href="https://doi.org/10.3390/ijms26157358" target="_blank" class="btn">View Publication</a>
      </div>

      <div class="project-card">
        <h3>CLEVER</h3>
        <p>
          <strong>Under Review</strong><br>
          Consensus-based reasoning with locally deployed LLMs for structured data extraction from surgical pathology reports.
          Achieves 92% accuracy in extracting clinical information from unstructured text.
        </p>
        <a href="https://doi.org/10.1101/2025.04.22.25326217" target="_blank" class="btn">View Preprint</a>
      </div>

      <div class="project-card">
        <h3>EAGLE</h3>
        <p>
          <strong>Under Review</strong><br>
          Efficient Alignment of Generalized Latent Embeddings for multimodal survival prediction with interpretable attribution analysis.
          Advances cross-modality correlation analysis for treatment outcome prediction.
        </p>
        <a href="https://arxiv.org/abs/2506.22446" target="_blank" class="btn">View Preprint</a>
      </div>
    </div>
  </SectionContainer>
</Layout>

<style>
  .research-area {
    margin-bottom: 2rem;
  }
  
  .research-area h3 {
    color: var(--color-primary);
    margin-bottom: 0.75rem;
  }
  
  .projects {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
    gap: 2rem;
  }
  
  .project-card {
    background-color: var(--color-light);
    padding: 1.5rem;
    border-radius: 8px;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
  }
  
  .project-card h3 {
    color: var(--color-primary);
    margin-bottom: 1rem;
  }
  
  .project-card p {
    margin-bottom: 1.5rem;
  }
  
  .btn {
    display: inline-block;
    background-color: var(--color-primary);
    color: white;
    padding: 0.5rem 1rem;
    border-radius: 4px;
    font-weight: 500;
    transition: background-color 0.3s ease;
  }
  
  .btn:hover {
    background-color: #0051bb;
    text-decoration: none;
  }
  
  @media (max-width: 768px) {
    .projects {
      grid-template-columns: 1fr;
    }
  }
</style>